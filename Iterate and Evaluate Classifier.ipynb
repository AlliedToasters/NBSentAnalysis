{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Naive Bayes Sentiment Analysis Challenge</H1><br><br>\n",
    "I really want to overfit this time.<br><br>\n",
    "Sentiment raw data was taken from the <a href='https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences'>UCI Machine Learning Repository.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Class Imbalance</H2><br><br>\n",
    "It turns out that all three data sets have exacty 1000 points, 500 positive and 500 negative. There is no class imbalance here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('amazon_cells_labelled.txt', engine='python', header=None, sep=None)\n",
    "data.columns = ['text', 'sentiment']\n",
    "data['positive_sentiment'] = np.where((data.sentiment == 1), True, False)\n",
    "\n",
    "def get_words(series):\n",
    "    words = []\n",
    "    for item in series: \n",
    "        words += item #put all words in same list\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    for i, word in enumerate(words):\n",
    "        word = word.translate(translator)\n",
    "        words[i] = word #strip away punctutation\n",
    "    return words\n",
    "\n",
    "positive_words = pd.Series(get_words(data[data['sentiment'] == 1].text.str.lower().str.split()))\n",
    "negative_words = pd.Series(get_words(data[data['sentiment'] == 0].text.str.lower().str.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg = list(negative_words.value_counts().index)\n",
    "pos = list(positive_words.value_counts().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = neg + pos #simply grab all words for keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keywords:\n",
    "    re_string = '[^a-zA-Z]' + key + '[^a-zA-Z]' #to match words with spaces or punctuations around only\n",
    "    data[str(key)] = data.text.apply(lambda x: bool(re.search(re_string, str(x), re.IGNORECASE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bnb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit = bnb.fit(data[keywords], data.positive_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     767\n",
       "False    233\n",
       "dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions = np.where((overfit.predict(data[keywords]) == data.positive_sentiment), True, False)\n",
    "pd.Series(correct_predictions).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still only have 77% accuracy on the training data...<br>\n",
    "Let's try training on one half of the data set and running it against the other half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holdout = BernoulliNB().fit(data.iloc[:500][keywords], data.positive_sentiment.iloc[:500])\n",
    "#the distribution of positive and negative sentiments among our points is even, so splitting it like this\n",
    "#still avoids class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     258\n",
       "False    242\n",
       "dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions = np.where((holdout.predict(data.iloc[500:][keywords]) == data.iloc[500:].positive_sentiment), True, False)\n",
    "pd.Series(correct_predictions).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     316\n",
       "False    184\n",
       "dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions = np.where((holdout.predict(data.iloc[:500][keywords]) == data.iloc[:500].positive_sentiment), True, False)\n",
    "pd.Series(correct_predictions).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see about 64% accuracy with the training group. With the holdout group, we see about 50% accuracy, which is as good as guessing all positive or all negative. <B>This is because there is no class imbalance here: all three data sets have exactly 500 positive and 500 negative points.</B> This looks like overfitting to me.<br>\n",
    "Let's compare these two models against the other data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imdb_data = pd.read_csv('imdb_labelled.txt', engine='python', header=None, sep='\\t', quoting=3)\n",
    "imdb_data.columns = ['text', 'sentiment']\n",
    "imdb_data['positive_sentiment'] = np.where((imdb_data.sentiment == 1), True, False)\n",
    "for key in keywords:\n",
    "    re_string = '[^a-zA-Z]' + key + '[^a-zA-Z]' #to match words with spaces or punctuations around only\n",
    "    imdb_data[str(key)] = imdb_data.text.apply(lambda x: bool(re.search(re_string, str(x), re.IGNORECASE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     610\n",
       "False    390\n",
       "dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions = np.where((overfit.predict(imdb_data[keywords]) == imdb_data.positive_sentiment), True, False)\n",
    "pd.Series(correct_predictions).value_counts()  #'overfit' model against imdb set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     532\n",
       "False    468\n",
       "dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions = np.where((holdout.predict(imdb_data[keywords]) == imdb_data.positive_sentiment), True, False)\n",
    "pd.Series(correct_predictions).value_counts() #'holdout' model against imdb set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yelp_data = pd.read_csv('yelp_labelled.txt', engine='python', header=None, sep='\\t', quoting=3)\n",
    "yelp_data.columns = ['text', 'sentiment']\n",
    "yelp_data['positive_sentiment'] = np.where((yelp_data.sentiment == 1), True, False)\n",
    "for key in keywords:\n",
    "    re_string = '[^a-zA-Z]' + key + '[^a-zA-Z]' #to match words with spaces or punctuations around only\n",
    "    yelp_data[str(key)] = yelp_data.text.apply(lambda x: bool(re.search(re_string, str(x), re.IGNORECASE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     583\n",
       "False    417\n",
       "dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions = np.where((overfit.predict(yelp_data[keywords]) == yelp_data.positive_sentiment), True, False)\n",
    "pd.Series(correct_predictions).value_counts() #'overfit' model against yelp set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     515\n",
       "False    485\n",
       "dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_predictions = np.where((holdout.predict(yelp_data[keywords]) == yelp_data.positive_sentiment), True, False)\n",
    "pd.Series(correct_predictions).value_counts() #'holdout' model against yelp set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Did we overfit?</H2><br><br>\n",
    "I'd say we did! Our 'overfit' and 'holdout' models both give a 50%-60% performance against the other sets, and the holdout test suggests overfitting even within our training set. I'd say that using every single word as a feature is a pretty lousy strategy overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
